{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbF6rb0Jqu9wQJlNFfnqci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra-mds/CS5660/blob/main/CS5660_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "60PqjLOMRJnB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tarfile\n",
        "import os\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.special import log_softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_directory = os.getcwd()\n",
        "\n",
        "print(\"Current working directory:\", current_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da1w1r__Up-j",
        "outputId": "e709062f-761a-44dd-f221-d15e96f7f0fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fvecs_from_tar(tar_filename, fvecs_filename):\n",
        "    with tarfile.open(tar_filename, 'r') as tar:\n",
        "        # Extract the fvecs file from the tar archive\n",
        "        fvecs_file = tar.extractfile(fvecs_filename)\n",
        "        with fvecs_file as f:\n",
        "          fv = np.frombuffer(f.read(), dtype=np.float32)\n",
        "          if fv.size == 0:\n",
        "            return np.zeros((0, 0))\n",
        "        dim = fv.view(np.int32)[0]\n",
        "        fv = fv.reshape(-1, 1 + dim)\n",
        "        if not all(fv.view(np.int32)[:, 0] == dim):\n",
        "          raise IOError(\"Non-uniform vector sizes in \" + fvecs_file)\n",
        "        fv = fv[:, 1:]\n",
        "        fv = fv.copy()\n",
        "    return fv"
      ],
      "metadata": {
        "id": "D0Jiou6ZSjRN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ivecs_from_tar(tar_filename, ivecs_filename):\n",
        "    with tarfile.open(tar_filename, 'r') as tar:\n",
        "        # Extract the ivecs file from the tar archive\n",
        "        ivecs_file = tar.extractfile(ivecs_filename)\n",
        "        with ivecs_file as f:\n",
        "          a = np.frombuffer(f.read(), dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().reshape(-1)"
      ],
      "metadata": {
        "id": "2if0T-jKTKvN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the Images and Labels"
      ],
      "metadata": {
        "id": "-IZav8k6WHos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the compressed .tgz file is uploaded to session data i.e. in \\content"
      ],
      "metadata": {
        "id": "Owud8dVtgWWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar_file = 'groupFungus_k64_nclass10_nex10.tgz'\n",
        "folder = 'example_data'\n",
        "fungus10_train_images = os.path.join(folder, 'groupFungus_k64_nclass10_nex10_Xtrain.fvecs')\n",
        "fungus10_train_labels = os.path.join(folder, 'groupFungus_k64_nclass10_nex10_Ltrain.ivecs')"
      ],
      "metadata": {
        "id": "O4uKMTvbTXgx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fungus10_test_images = os.path.join(folder, 'groupFungus_k64_nclass10_nex10_Xtest.fvecs')\n",
        "fungus10_test_labels = os.path.join(folder, 'groupFungus_k64_nclass10_nex10_Ltest.ivecs')"
      ],
      "metadata": {
        "id": "kvrWLcx3fiL8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fungus10_train_images_features = load_fvecs_from_tar(tar_file, fungus10_train_images)\n",
        "fungus10_test_images_features = load_fvecs_from_tar(tar_file, fungus10_test_images)"
      ],
      "metadata": {
        "id": "fDbH_mEZT67m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fungus10_train_images_features.shape, fungus10_test_images_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2dbYiJHcNGD",
        "outputId": "30815ea7-2474-4821-d3f2-f463e91b8562"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 4096), (100, 4096))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fungus10_train_images_labels = load_ivecs_from_tar(tar_file, fungus10_train_labels)\n",
        "fungus10_test_images_labels = load_ivecs_from_tar(tar_file, fungus10_test_labels)"
      ],
      "metadata": {
        "id": "GwjaAyQocj-4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fungus10_train_images_labels.shape, fungus10_test_images_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wkQu1BQcxA3",
        "outputId": "e6d67a6c-36f0-4ee0-860a-9db5bcb142d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100,), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a Linear model as described in the paper"
      ],
      "metadata": {
        "id": "xB11GPXpcvS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First create a one hot encoded array for true values"
      ],
      "metadata": {
        "id": "m5ChoCs03Fui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define one hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "# transform data\n",
        "y_train_true = encoder.fit_transform(fungus10_train_images_labels.reshape(100,1))\n",
        "print(y_train_true[0])"
      ],
      "metadata": {
        "id": "91Kios_0uNIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25425b95-5784-4d4c-89cd-b3579a0e0c64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build X matrix and Weight matrix based on dimensions of the data"
      ],
      "metadata": {
        "id": "PbGI42h93LON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = fungus10_train_images_features"
      ],
      "metadata": {
        "id": "Pu1AWfLAdyB1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLXDvgNN5KZ1",
        "outputId": "76897878-f9e8-416b-81cf-e8becfc73fbf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4096)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight matrix would have:\n",
        "\n",
        "\n",
        "*   rows = no. of features\n",
        "*   columns = no. of classes"
      ],
      "metadata": {
        "id": "iB8vVaSp3Yqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(5660)\n",
        "_,m = fungus10_train_images_features.shape\n",
        "n = len(set(fungus10_train_images_labels))\n",
        "W = np.random.uniform(low=-1, high=1, size=(m, n))\n",
        "b = np.random.uniform(low=-1, high=1, size=(1, n))"
      ],
      "metadata": {
        "id": "H52bKyLS3YBH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acfQJHOO5R05",
        "outputId": "07678c5e-4a33-4d0f-c6dc-520ba4ca6f49"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4096, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial set of weights"
      ],
      "metadata": {
        "id": "xWwqOpN14W3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(W[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu2XdYmp4ZPO",
        "outputId": "6cbc8290-5f08-4711-90a8-787e76fad4cf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.44140127  0.4690655  -0.73259887 -0.05906308 -0.53820052  0.8147641\n",
            "  -0.29529803 -0.04197371 -0.93145758  0.22377421]\n",
            " [ 0.92699897  0.97547102  0.64151833 -0.70370343 -0.62292231 -0.03680328\n",
            "   0.6366819   0.89381421  0.26542717  0.27011698]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cobE_KDh4gdB",
        "outputId": "bc107470-a16e-4df2-b2ed-59ea21ec9b7e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.56534233  0.93943885  0.91182578 -0.06911842 -0.09695704  0.69054724\n",
            "  -0.8612357  -0.32716141 -0.48437092 -0.82968288]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We multiply X (100,4096) with W(4096,10) and add b\n"
      ],
      "metadata": {
        "id": "O7aLlINa47s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U, singular_values, V = np.linalg.svd(W,full_matrices=False)"
      ],
      "metadata": {
        "id": "7H1QmnuYKdqD"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPRdHhHYKuDu",
        "outputId": "190ed2c9-3145-409a-9d3c-8cc09faac419"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4096, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "singular_values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5b_k0j0KoSX",
        "outputId": "b812a299-3938-4936-b283-423626eb3c96"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB8KibdhKz5A",
        "outputId": "a8b79653-1fc2-44ce-e16b-6916eb877ed3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trace_norm(matrix):\n",
        "    # Compute the singular value decomposition (SVD)\n",
        "    U, singular_values, Vh = np.linalg.svd(matrix,full_matrices=False)\n",
        "\n",
        "    # Compute the trace norm as the sum of singular values\n",
        "    trace_norm_value = np.sum(singular_values)\n",
        "\n",
        "    return trace_norm_value, U, Vh"
      ],
      "metadata": {
        "id": "EpQAzY9dBibj"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trace_norm(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p3Qrz9aElN4",
        "outputId": "1fbbb745-b8c3-45cd-df51-d0964570a2f0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369.0587225211235,\n",
              " array([[-0.00831505, -0.00791636,  0.01554518, ...,  0.02511323,\n",
              "          0.02438435, -0.00978903],\n",
              "        [ 0.02702271, -0.03117371, -0.0023663 , ...,  0.02158996,\n",
              "          0.00100944,  0.01075031],\n",
              "        [ 0.00793354,  0.02256807,  0.00276934, ...,  0.00359363,\n",
              "         -0.01292101,  0.00381469],\n",
              "        ...,\n",
              "        [-0.01166667,  0.00027402,  0.00970164, ...,  0.00852501,\n",
              "         -0.02850632,  0.01133839],\n",
              "        [ 0.00760792,  0.02417367,  0.00298942, ...,  0.01093301,\n",
              "         -0.01570748,  0.01854379],\n",
              "        [ 0.00262163, -0.0123304 , -0.00707363, ...,  0.02302851,\n",
              "          0.01409366, -0.0019847 ]]),\n",
              " array([[-0.06624644, -0.30462039,  0.33724594, -0.36608441, -0.46158238,\n",
              "         -0.13328142,  0.39911928,  0.49093928, -0.10774025, -0.11098397],\n",
              "        [-0.18838267, -0.47468404, -0.15659926,  0.42324781, -0.21111395,\n",
              "         -0.5697397 , -0.36175656, -0.00626457, -0.18261944, -0.04577824],\n",
              "        [ 0.28683724,  0.11513005, -0.01636647,  0.32821341, -0.0066542 ,\n",
              "          0.1281615 ,  0.25498893, -0.07761128, -0.55667222, -0.63172865],\n",
              "        [ 0.64597976, -0.07696281, -0.04259103, -0.3763453 ,  0.18485454,\n",
              "         -0.1412768 , -0.51288008,  0.29708784, -0.02789807, -0.16468546],\n",
              "        [-0.22770938,  0.10347119, -0.6973673 , -0.19799684,  0.34824097,\n",
              "         -0.24946317,  0.30712542,  0.34021594, -0.13328958, -0.02399116],\n",
              "        [ 0.02490715, -0.62077322, -0.39257506, -0.12165576, -0.08349959,\n",
              "          0.4448366 ,  0.05553162, -0.20289339,  0.32390259, -0.3018125 ],\n",
              "        [ 0.08559253, -0.35193625, -0.01869971, -0.1306533 ,  0.13644436,\n",
              "          0.2771858 ,  0.01760543, -0.11907105, -0.65398518,  0.56014401],\n",
              "        [ 0.37927338,  0.18291935, -0.38331172,  0.36290937, -0.52114525,\n",
              "          0.19822158,  0.04605461,  0.32388078,  0.09930447,  0.3410217 ],\n",
              "        [-0.19923209,  0.32497265, -0.26092363, -0.46854192, -0.53509046,\n",
              "         -0.01100425, -0.28009164, -0.35441077, -0.25376553, -0.11040167],\n",
              "        [ 0.46606673, -0.06092416, -0.06216881, -0.12319   , -0.05815441,\n",
              "         -0.49486554,  0.451086  , -0.5128922 ,  0.14052035,  0.15960114]]))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def net_input(X, W, b):\n",
        "    return (X.dot(W) + b)\n",
        "\n",
        "net_in = net_input(X_train, W, b)\n",
        "print(f'net input shape:\\n {net_in.shape}')\n",
        "print(f'net input:\\n {net_in[:2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqkhH2JI43LX",
        "outputId": "fb4faeaa-e60f-476f-c550-35390ec9ac96"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net input shape:\n",
            " (100, 10)\n",
            "net input:\n",
            " [[ 0.6954171   0.77256549  0.18707491 -0.08701527  0.17142897  0.9085162\n",
            "  -0.27257828 -0.1387958   0.57632682 -0.92504999]\n",
            " [ 0.30649441  0.82180241  0.71058519  0.39058976 -0.93494618  0.8043387\n",
            "   0.41005151 -0.31011337  0.16902247 -1.34038849]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
        "\n",
        "smax = softmax(net_in)\n",
        "print(f'softmax:\\n {smax[:2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OZ8IpIo7mUj",
        "outputId": "ec31ee20-c62c-45d1-95d3-a21a5e155eee"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax:\n",
            " [[0.14559767 0.15727494 0.08757582 0.0665807  0.08621628 0.18017817\n",
            "  0.05530436 0.06322085 0.12925108 0.02880013]\n",
            " [0.10093817 0.16898605 0.15119931 0.10979374 0.02916786 0.16606054\n",
            "  0.11195145 0.05448363 0.08797355 0.01944569]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get class labels from Probabilities"
      ],
      "metadata": {
        "id": "RpPUhzah75P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_classlabel(z):\n",
        "    return z.argmax(axis=1)\n",
        "\n",
        "print(f'predicted class labels:  {to_classlabel(smax)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCyQ-7gi74jJ",
        "outputId": "5d71d14b-20e7-40d2-96e4-73f9bb1ff7e7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted class labels:  [5 1 2 1 1 4 2 2 0 1 1 2 2 2 5 0 0 1 0 0 1 2 1 2 5 2 2 5 1 5 0 0 5 1 1 5 1\n",
            " 1 0 1 2 5 1 1 2 2 1 1 5 0 1 1 1 5 5 1 2 5 1 1 2 1 0 1 1 1 1 2 2 5 5 5 2 1\n",
            " 2 1 4 1 1 5 1 2 5 5 2 3 1 8 1 2 5 0 5 1 1 5 1 2 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_loss(X,W,b,y_true):\n",
        "  prob_scores = softmax(net_input(X, W, b))\n",
        "  class_ = np.argmax(y_true,axis=1)\n",
        "  print(class_[:3])\n",
        "  print(prob_scores[:3])\n",
        "  numerator=np.exp(prob_scores[np.arange(prob_scores.shape[0]), class_])\n",
        "  print(numerator[:3])\n",
        "  exp_arr = np.exp(prob_scores)\n",
        "  # Sum along the columns\n",
        "  denominator = np.sum(exp_arr, axis=1)\n",
        "  print(denominator[:3])\n",
        "  return -np.log(numerator/denominator)"
      ],
      "metadata": {
        "id": "w2mBrh1J8A5U"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-np.log(1.1567307/11.06421201)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpUWwJyTUwbl",
        "outputId": "307664c4-3c70-4bb9-af06-b2d70f86c6af"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.258118092337486"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_loss(X=X_train,W=W,b=b, y_true=y_train_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRMy8mAK_BJX",
        "outputId": "413db8ac-d53d-4043-8907-4995e9e931d3"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0]\n",
            "[[0.14559767 0.15727494 0.08757582 0.0665807  0.08621628 0.18017817\n",
            "  0.05530436 0.06322085 0.12925108 0.02880013]\n",
            " [0.10093817 0.16898605 0.15119931 0.10979374 0.02916786 0.16606054\n",
            "  0.11195145 0.05448363 0.08797355 0.01944569]\n",
            " [0.16501321 0.10825541 0.31217767 0.04838716 0.10451748 0.17874175\n",
            "  0.01937003 0.01594746 0.03426979 0.01332004]]\n",
            "[1.1567307  1.10620824 1.1794087 ]\n",
            "[11.06421201 11.06587916 11.09950916]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.25811809, 2.30292825, 2.24188767, 2.25546786, 2.27337698,\n",
              "       2.2537862 , 2.27784808, 2.33787005, 2.21473731, 2.26940773,\n",
              "       2.10931841, 2.24261581, 2.22779101, 2.1876584 , 2.1955556 ,\n",
              "       2.30187499, 2.25377058, 2.07600046, 2.2653692 , 2.21552681,\n",
              "       2.29628449, 2.13150489, 2.32256296, 2.1400521 , 2.31832672,\n",
              "       2.20052384, 1.94860998, 2.30356075, 2.17171822, 2.23453273,\n",
              "       2.38977056, 2.31662683, 2.36434443, 2.32640448, 2.30766442,\n",
              "       2.3313598 , 2.28966666, 2.32053657, 2.23610642, 2.36002961,\n",
              "       2.39025754, 2.36503353, 2.35184703, 2.36237398, 2.33963582,\n",
              "       2.34623991, 2.35442028, 2.35618442, 2.28769293, 2.3674473 ,\n",
              "       2.35384477, 2.33888315, 2.26548385, 2.19395904, 2.22674067,\n",
              "       2.26721999, 2.14350828, 2.11731159, 2.22056804, 2.34533955,\n",
              "       2.35143615, 2.35878726, 2.38783251, 2.38201617, 2.38204172,\n",
              "       2.35238012, 2.40665371, 2.37012097, 2.36953712, 2.39598201,\n",
              "       2.37204759, 2.28234983, 2.38479341, 2.34245392, 2.37897358,\n",
              "       2.37089404, 2.32280774, 2.37403918, 2.28133658, 2.35528326,\n",
              "       2.36724443, 2.38106003, 2.34594661, 2.37611601, 2.37385499,\n",
              "       2.35566893, 2.35080077, 2.16294443, 2.3189355 , 2.29434211,\n",
              "       2.35675622, 2.38279541, 2.36039966, 2.37791564, 2.37531366,\n",
              "       2.33267892, 2.37280148, 2.38741337, 2.38792931, 2.38838466])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def regularization_penalty(W, lambda_=10**-2):\n",
        "  trace_norm_,_,_ = trace_norm(W)\n",
        "  return lambda_*(trace_norm_**2)"
      ],
      "metadata": {
        "id": "-VHeuYOwH1DU"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X, W, b, y_true, lambda_=10**-2):\n",
        "  regularizer = regularization_penalty(W)\n",
        "  return np.mean([logistic_loss(X=X_train[i],W=W,b=b, y_true=y_train_true[i])+regularizer for i in range(len(X))])"
      ],
      "metadata": {
        "id": "RhPMMjgqAzol"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss(X_train, W, b, y_train_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa4uF7NFBTgB",
        "outputId": "e30c6e73-621b-45de-9b3e-a4a5e9c07af5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1364.3574367860135"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRf7qwr4SMdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_regularizer(W, lambda_=10**-2):\n",
        "  trace_norm_, U, Vh = trace_norm(W)\n",
        "  gradient = np.matmul(U,Vh)\n",
        "  gradient = 2*lambda_*trace_norm_*(gradient)\n",
        "  return gradient"
      ],
      "metadata": {
        "id": "HC6iJPBnIP5_"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_regularizer(W).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGbZqUVrJ_Xl",
        "outputId": "000a54eb-8179-4147-b7e5-99855ede9aca"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4096, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SubgradientDescent():\n",
        "\n",
        "    \"\"\"Softmax regression classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float (default: 0.01)\n",
        "        Learning rate (between 0.0 and 1.0)\n",
        "    epochs : int (default: 50)\n",
        "        Passes over the training dataset.\n",
        "        Prior to each epoch, the dataset is shuffled\n",
        "        if `minibatches > 1` to prevent cycles in stochastic gradient descent.\n",
        "    minibatches : int (default: 1)\n",
        "        The number of minibatches for gradient-based optimization.\n",
        "        If 1: Gradient Descent learning\n",
        "        If len(y): Stochastic Gradient Descent (SGD) online learning\n",
        "        If 1 < minibatches < len(y): SGD Minibatch learning\n",
        "    random_seed : int (default: None)\n",
        "        Set random state for shuffling and initializing the weights.\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 2d-array, shape={n_features, 1}\n",
        "      Model weights after fitting.\n",
        "    b_ : 1d-array, shape={1,}\n",
        "      Bias unit after fitting.\n",
        "    cost_ : list\n",
        "        List of floats, the average log loss for each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 eta=0.01,\n",
        "                 epochs=50,\n",
        "                 lambda_=10**-2,\n",
        "                 minibatches=1,\n",
        "                 n_classes=10,\n",
        "                 random_seed=5660):\n",
        "        self.eta = eta\n",
        "        self.epochs = epochs\n",
        "        self.lambda_ = lambda_\n",
        "        self.minibatches = minibatches\n",
        "        self.n_classes = n_classes\n",
        "        self.random_seed = random_seed\n",
        "        self._encoder = None\n",
        "\n",
        "    def _init_params(self, weights_shape, bias_shape=(1,), dtype='float64',\n",
        "                     scale=0.01, random_seed=5660):\n",
        "        \"\"\"Initialize weight coefficients.\"\"\"\n",
        "        np.random.seed(random_seed)\n",
        "        w = np.random.normal(loc=0.0, scale=scale, size=weights_shape)\n",
        "        b = np.zeros(shape=bias_shape)\n",
        "        return b.astype(dtype), w.astype(dtype)\n",
        "\n",
        "    def _fit(self, X, y, init_params=True):\n",
        "        if init_params:\n",
        "            self._n_features = X.shape[1]\n",
        "\n",
        "            self.b_, self.w_ = self._init_params(\n",
        "                weights_shape=(self._n_features, self.n_classes),\n",
        "                bias_shape=(self.n_classes,),\n",
        "                random_seed=self.random_seed)\n",
        "            self.cost_ = []\n",
        "\n",
        "        y_enc = self._one_hot(y=y)\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "            print(f'Epoch#:{i}')\n",
        "            for idx in self._yield_minibatches_idx(\n",
        "                    n_batches=self.minibatches,\n",
        "                    data_ary=y,\n",
        "                    shuffle=True):\n",
        "                # givens:\n",
        "                # w_ -> n_feat x n_classes\n",
        "                # b_  -> n_classes\n",
        "\n",
        "                # net_input, softmax and diff -> n_samples x n_classes:\n",
        "                logistic_loss_gradient = self._logistic_loss_gradient(X[idx],y_enc[idx])\n",
        "                print(f\"logistic_loss_gradient shape = {logistic_loss_gradient.shape}\")\n",
        "                mse = -1.0*np.mean(logistic_loss_gradient, axis=0)\n",
        "                print(f'mse:{mse}')\n",
        "\n",
        "                # gradient -> n_features x n_classes\n",
        "                regularizer_gradient = self._regularizer_gradient()\n",
        "                print(f'regularizer_gradient shape:{regularizer_gradient.shape}')\n",
        "                grad = logistic_loss_gradient + regularizer_gradient\n",
        "\n",
        "                # update in opp. direction of the cost gradient\n",
        "                self.w_ -= (self.eta * grad +\n",
        "                            self.eta * self.lambda_ * self.w_)\n",
        "                self.b_ -= (self.eta * np.sum(-1*logistic_loss_gradient, axis=0))\n",
        "\n",
        "            # compute cost of the whole epoch\n",
        "            cost = self._cost(X, y_enc)\n",
        "            print(f'Epcoh Cost:{cost}')\n",
        "            self.cost_.append(cost)\n",
        "        return self\n",
        "\n",
        "    def fit(self, X, y, init_params=True):\n",
        "        \"\"\"Learn model from training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.\n",
        "        init_params : bool (default: True)\n",
        "            Re-initializes model parametersprior to fitting.\n",
        "            Set False to continue training with weights from\n",
        "            a previous model fitting.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        if self.random_seed is not None:\n",
        "            np.random.seed(self.random_seed)\n",
        "        self._fit(X=X, y=y, init_params=init_params)\n",
        "        self._is_fitted = True\n",
        "        return self\n",
        "\n",
        "    def _predict(self, X):\n",
        "        probas = self.predict_proba(X)\n",
        "        return self._to_classlabels(probas)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict targets from X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        target_values : array-like, shape = [n_samples]\n",
        "          Predicted target values.\n",
        "\n",
        "        \"\"\"\n",
        "        if not self._is_fitted:\n",
        "            raise AttributeError('Model is not fitted, yet.')\n",
        "        return self._predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict class probabilities of X from the net input.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        Class probabilties : array-like, shape= [n_samples, n_classes]\n",
        "\n",
        "        \"\"\"\n",
        "        net = self._net_input(X, self.w_, self.b_)\n",
        "        softm = self._softmax(net)\n",
        "        return softm\n",
        "\n",
        "    def _net_input(self, X, W, b):\n",
        "        return (X.dot(W) + b)\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
        "\n",
        "    def _trace_norm(self):\n",
        "      # Compute the singular value decomposition (SVD)\n",
        "      U, singular_values, Vh = np.linalg.svd(self.w_,full_matrices=False)\n",
        "\n",
        "      # Compute the trace norm as the sum of singular values\n",
        "      trace_norm_value = np.sum(singular_values)\n",
        "\n",
        "      return trace_norm_value, U, Vh\n",
        "\n",
        "    def _regularizer_gradient(self):\n",
        "      trace_norm_, U, Vh = self._trace_norm()\n",
        "      gradient = np.matmul(U,Vh)\n",
        "      gradient = 2*self.lambda_*trace_norm_*(gradient)\n",
        "      return gradient\n",
        "\n",
        "    def _logistic_loss_gradient(self, X, y_true):\n",
        "      net = self._net_input(X, self.w_, self.b_)\n",
        "      softm = self._softmax(net)\n",
        "      diff = softm - y_true\n",
        "      gradient = -1*diff\n",
        "      return gradient\n",
        "\n",
        "    def logistic_loss(self, X, y_true):\n",
        "      prob_scores = softmax(net_input(X, self.w_, self.b_))\n",
        "      class_ = np.argmax(y_true,axis=1)\n",
        "      numerator=np.exp(prob_scores[np.arange(prob_scores.shape[0]), class_])\n",
        "      exp_arr = np.exp(prob_scores)\n",
        "      # Sum along the columns\n",
        "      denominator = np.sum(exp_arr, axis=1)\n",
        "      return -np.log(numerator/denominator)\n",
        "\n",
        "    def regularization_penalty(self, lambda_=10**-2):\n",
        "      trace_norm_,_,_ = self._trace_norm()\n",
        "      return lambda_*(trace_norm_**2)\n",
        "\n",
        "    def _cost(self, X, y_true, lambda_=10**-2):\n",
        "      regularizer_penalty_ = self.regularization_penalty()\n",
        "      logistic_loss_ = self.logistic_loss(X, y_true)\n",
        "      cost_ = logistic_loss_+regularizer_penalty_\n",
        "      return np.mean(cost_)\n",
        "\n",
        "\n",
        "    def _to_classlabels(self, z):\n",
        "        return z.argmax(axis=1)\n",
        "\n",
        "    def _one_hot(self, y):\n",
        "      # define one hot encoding\n",
        "      self._encoder = OneHotEncoder(sparse_output=False)\n",
        "      # transform data\n",
        "      return encoder.fit_transform(y.reshape(len(y),1))\n",
        "\n",
        "\n",
        "    def _yield_minibatches_idx(self, n_batches, data_ary, shuffle=True):\n",
        "            indices = np.arange(data_ary.shape[0])\n",
        "\n",
        "            if shuffle:\n",
        "                indices = np.random.permutation(indices)\n",
        "            if n_batches > 1:\n",
        "                remainder = data_ary.shape[0] % n_batches\n",
        "\n",
        "                if remainder:\n",
        "                    minis = np.array_split(indices[:-remainder], n_batches)\n",
        "                    minis[-1] = np.concatenate((minis[-1],\n",
        "                                                indices[-remainder:]),\n",
        "                                               axis=0)\n",
        "                else:\n",
        "                    minis = np.array_split(indices, n_batches)\n",
        "\n",
        "            else:\n",
        "                minis = (indices,)\n",
        "\n",
        "            for idx_batch in minis:\n",
        "                yield idx_batch"
      ],
      "metadata": {
        "id": "YKc0TZBOM1by"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = SubgradientDescent(eta=0.01, epochs=10, minibatches=1, random_seed=5660, )\n",
        "lr.fit(X_train, fungus10_train_images_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ehFXeymugucV",
        "outputId": "fe53ef40-0369-4c7c-e828-57195109b354"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch#:0\n",
            "logistic_loss_gradient shape = (100, 10)\n",
            "mse:[-2.87833665e-04 -5.66878791e-05  2.07955529e-04 -3.56364984e-04\n",
            " -1.15820267e-04 -3.08870312e-04  1.91899360e-04  2.14790122e-04\n",
            "  2.50959423e-04  2.59972673e-04]\n",
            "regularizer_gradient shape:(4096, 10)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (100,10) (4096,10) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-5aed73afff76>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubgradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5660\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfungus10_train_images_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-173-864933a803c6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, init_params)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-173-864933a803c6>\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, init_params)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mregularizer_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regularizer_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'regularizer_gradient shape:{regularizer_gradient.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_loss_gradient\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularizer_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# update in opp. direction of the cost gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,10) (4096,10) "
          ]
        }
      ]
    }
  ]
}